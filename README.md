# Site Page Crawl and Redirected Page Crawl

This is a simple script that scans a domain for all redirected pages and links. It follows links, identifies any redirected URLs, and saves both the redirected pages and all visited links into separate files.

## How to Use

1. Clone the repository:
    ```bash
    git clone https://github.com/who0ze/Site-Page-Crawl-and-Redirected-Page-Crawl
    ```

2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the script:
    ```bash
    python sitesearch.py
    ```

4. You will be prompted to enter the domain and select the language (English or Turkish). The scan results will be saved in `site_page.txt` and `redirect_links.txt`.

## License

This project is licensed under the MIT License - see the [LICENSE.txt](LICENSE.txt) file for details.


## Author

Created by **who0ze**  
GitHub: [https://github.com/who0ze](https://github.com/who0ze)
